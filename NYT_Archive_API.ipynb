{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0- Importing libraries and setting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time \n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "#Progress bar for pandas\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from pandas import json_normalize\n",
    "\n",
    "NYT_API_KEY = 'YOUR API KEY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_start, year_end = 2010, 2019\n",
    "\n",
    "API_DIRECTORY_PATH = './NYT_API_RAW/'\n",
    "PARSED_DIRECTORY_PATH = './NYT_clean_data/'\n",
    "\n",
    "if ~os.path.exists(API_DIRECTORY_PATH):\n",
    "    os.makedirs(API_DIRECTORY_PATH)\n",
    "\n",
    "if ~os.path.exists(PARSED_DIRECTORY_PATH):\n",
    "    os.makedirs(PARSED_DIRECTORY_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1- Archive API request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GET_NYT_archive_API(year_start = 1980, year_end = 2023, directory_path = ''):\n",
    "\n",
    "    ''''\n",
    "    Function to get the data fron the NYT Archive API\n",
    "    '''\n",
    "    \n",
    "    file_path = directory_path + \"NYT_Archive_API_\" + str(year_start) + \"_\" + str(year_end) +\".csv\"\n",
    "    print(file_path)\n",
    "    #Seed df to get the structure of the reply from the NYT API\n",
    "    year = 2000\n",
    "    month = 1\n",
    "\n",
    "    #WEB URL of the archive API\n",
    "    NYT_ARCHIVE = requests.get('https://api.nytimes.com/svc/archive/v1/' + str(year) + '/' + str(month) + '.json?api-key=' + NYT_API_KEY)\n",
    "    j = NYT_ARCHIVE.json()['response']['docs']\n",
    "\n",
    "    NYT_df = pd.DataFrame(columns=pd.DataFrame.from_dict(j).columns)\n",
    "\n",
    "    for year in range(year_start, year_end+1):\n",
    "        NYT_df_temp_year = pd.DataFrame(columns = NYT_df.columns)\n",
    "\n",
    "        for month in range(1, 13):           \n",
    "            time.sleep(15) #To stay below the 10 request per minute limit\n",
    "            \n",
    "            try:\n",
    "                NYT_ARCHIVE = requests.get('https://api.nytimes.com/svc/archive/v1/' + str(year) + '/' + str(month) + '.json?api-key=' + NYT_API_KEY)\n",
    "                print( str(month) + \" - \" +  str(year) + \" - \" + str(len(NYT_ARCHIVE.json()['response']['docs'])))\n",
    "                j = NYT_ARCHIVE.json()['response']['docs']\n",
    "                NYT_df_temp_month = pd.DataFrame.from_dict(j)\n",
    "                NYT_df_temp_year = pd.concat([NYT_df_temp_year, NYT_df_temp_month])\n",
    "\n",
    "            except:\n",
    "                print( str(month) + \" - \" +  str(year) + ' - ' + str(NYT_ARCHIVE) + ' - FAIL')\n",
    "\n",
    "        NYT_df = pd.concat([NYT_df, NYT_df_temp_year], axis =0)\n",
    "\n",
    "    NYT_df = NYT_df.reset_index(drop=True)\n",
    "    print('Export begin')\n",
    "    NYT_df.to_csv(file_path, index=False)\n",
    "    print('Export finish')\n",
    "\n",
    "    return NYT_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NYT_df = GET_NYT_archive_API(year_start, year_end, API_DIRECTORY_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2- Cleaning and parsing NYT data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KeywordParser(json):\n",
    "\n",
    "    ''' \n",
    "    Parse the 5 top keywords from the NYT data in their order of importance\n",
    "    '''\n",
    "    \n",
    "    array_1 = np.empty(5, dtype=object)\n",
    "    array_1[:]= np.nan\n",
    "    array_2 = json_normalize(eval(json)).values[:5,1:2].flatten()\n",
    "    array_1[:len(array_2)] = array_2\n",
    "\n",
    "    return pd.Series(array_1.reshape(5))\n",
    "\n",
    "def NYT_data_cleaning_parsing(NYT_df, directory_path = ''):\n",
    "\n",
    "    '''\n",
    "    Parse and clean the NYT raw output\n",
    "    '''\n",
    "\n",
    "    file_path = directory_path + \"NYT_Articles_\" + str(year_start) + '_' + str(year_end) + \".csv\"\n",
    "    print(file_path)\n",
    "    print(NYT_df.shape)\n",
    "\n",
    "    print(NYT_df.shape)\n",
    "\n",
    "    ##PARSING\n",
    "    #Setting the date column in a DateTime format\n",
    "    NYT_df['pub_date'] = pd.to_datetime(NYT_df['pub_date'])\n",
    "\n",
    "    #Remove irrelevent columns\n",
    "    NYT_df = NYT_df.drop([\"multimedia\", \"print_section\",\"print_page\", \"source\", \"_id\", \"word_count\", \"uri\", \"snippet\", \"lead_paragraph\"], axis = 1)\n",
    "\n",
    "    #Types of articles to keep\n",
    "    type_of_material_to_keep = ['Archives', 'An Analysis', 'Editorial', 'Interactive Feature', 'News', 'News Analysis', 'Newsletter', 'Op-Ed', 'Quote', 'Review', 'Slideshow', 'briefing']\n",
    "    NYT_df = NYT_df[NYT_df[\"type_of_material\"].isin(type_of_material_to_keep)]\n",
    "\n",
    "    #Remove empty abstract entries\n",
    "    NYT_df = NYT_df[NYT_df['abstract'].notna()]\n",
    "    NYT_df.reset_index(drop = True, inplace = True)\n",
    "\n",
    "    #Parse headline data and keep main\n",
    "    df_headline = pd.json_normalize(NYT_df.headline[:])\n",
    "    NYT_df['headline'] = df_headline['main']\n",
    "\n",
    "    #Parse top 5 keywords\n",
    "    NYT_df[\"keywords\"] = NYT_df['keywords'].astype(str)\n",
    "    NYT_df[[\"keyword_1\", \"keyword_2\", \"keyword_3\", \"keyword_4\", \"keyword_5\"]] = NYT_df.keywords.progress_apply(KeywordParser)\n",
    "\n",
    "    #CLEANING\n",
    "    NYT_df = NYT_df[NYT_df['document_type'] == 'article']\n",
    "\n",
    "    to_remove = ['MOTION PICTURES']\n",
    "\n",
    "    for item_to_remove in to_remove:\n",
    "        NYT_df = NYT_df[NYT_df['keyword_1'] != item_to_remove]\n",
    "        NYT_df = NYT_df[NYT_df['keyword_2'] != item_to_remove]\n",
    "        NYT_df = NYT_df[NYT_df['keyword_3'] != item_to_remove]\n",
    "        NYT_df = NYT_df[NYT_df['keyword_4'] != item_to_remove]\n",
    "        NYT_df = NYT_df[NYT_df['keyword_5'] != item_to_remove]\n",
    "\n",
    "    #Format the column order\n",
    "    columns_order = [\n",
    "    'headline', \n",
    "    'abstract', \n",
    "    'pub_date', \n",
    "    'web_url',\n",
    "    'keyword_1',\n",
    "    'keyword_2',\n",
    "    'keyword_3',\n",
    "    'keyword_4',\n",
    "    'keyword_5']\n",
    "\n",
    "    NYT_df = NYT_df[columns_order]\n",
    "\n",
    "    NYT_df.reset_index(drop = True, inplace = True)\n",
    "    print(NYT_df.shape)\n",
    "    \n",
    "    NYT_df.to_csv(file_path, index=False)\n",
    "    \n",
    "    return NYT_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NYT_articles_df = NYT_data_cleaning_parsing(NYT_df, PARSED_DIRECTORY_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0794f36577fa0beb83ccaf51a63f86a37002180b326e5bb9f2533f841c35fc46"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
